---
title: "Delta Smelt Tagging - Burst analysis Expt 1"
author: "Anna Steel"
date: "11/02/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lme4)
library(circular)
library(patchwork)
library(MuMIn)

```

This code segment reads in the measurements of inter-laser distance taken from the tunnel (taken immediately before or after trials) and entered in the same format as Ken used in his initial tests in 2019 and 2020.   
  
It then manipulates these dataframes/tibbles to use merge with the burst files for each fish and calculate velocities.   
```{r read tunnel data}
# if running from the DS_Tagging project in AES laptop then the base wd is "/Users/Anna/Documents/ResearchGit/SturgContam"; but the wd will be wherever the project file is located and the pathnames here should be relative to that location. Two '..' in the file name indicates to go back one folder in the directory structure.

## Set up gate distances for use in code
tunnel_specs23 <- read_csv("../rawData/DS_Burst_Tunnel_Specs_08_2023_SG.csv")

tunnel_specs = tunnel_specs23[,c("GATE_ID_L", "INTERGATE_DISTANCES_CM","GATE_DISTANCES_CM_L")]
names(tunnel_specs) = c("GATE_ID","INTERGATE_DISTANCES","GATE_DISTANCES")

# We have code that will let us use each intergate distance, including overlapping gates, not just the sequential gates. For the sturgeon, The resulting numbers wern't that different, and I'm uncomfortable with the pseudoreplication of averaging across segments that overlap, So I've deleted it for now, and we will use only the sequential gates to keep the code more concise. 

```      
    
```{r read trial metadata}

# pull metadata for index to all trials and metadata
trial_specs <- read.csv("../rawData/Burst_Expt1_DS2023_MetaTrialdata.csv")

 # tidy up data types within the df
 trial_specs$treatment = factor(trial_specs$treatment, 
                                levels=c("FC","HC","LS","VS","LT","VT"))
 trial_specs[trial_specs=="N/A"] <- NA
 
# vector of all the file names to be considered in the analysis
filestart <- unique(trial_specs$raspPI_filestart)

 # remove trials without proper data file or terrible results that break the code
    #filestart = filestart[!(filestart %in% c("WSContam2022_Whit_R02_07_26_2022"))]

# read in necropsy data
necro_dat <- read.csv("../rawData/Burst_Expt1_DS2023_NecropsyData.csv")
 necro_dat$trialID = paste0("T",sprintf("%02.0f",necro_dat$trialID))
 
 # add to trial_specs
 trial_specs = merge(trial_specs, necro_dat[,c("trialID","sex","eggStage","tagID")], 
                                               all.x=T, by="trialID")

```


There are endless ways to use the burst events from one individual to estimate a 'burst speed' for that fish. See Ken's paper to understand what he considered and selected, and then look at if/how much those align with the methods considered here. For the juvenile sturgeon bursts, I selected to drop the fastest burst segment from each burst event, then average the next three highest segments to get an estimate of burst speed for that burst event. For each individual (multiple burst events) I then averaged the fastest three burst events to get an estimated burst speed for the individual. We will try that here as our first pass, and see how the results look. 

```{r create empty df for collection}

# create empty dataframe to record mean of top 3 burst velocities, after removing top 1; for each burst of each fish
burst.topvels = data.frame(treatmentrep = "EMPTY", burstID = NA, 
                           burstQual = as.factor(NA),
                          n_vels = NA, n_avg = NA, n_dropped = NA, start_side = NA,
                          mn.topburstvels = NA, sd.topburstvels = NA, CV.topburstvels.perc = NA)

# create empty dataframe to record above burst velocity averaged across the fastest three pre-filtered 'good' trials for each fish, as well as sd of bursts and and N good bursts for that individual (potential index of participation)
mean.topvels = data.frame(treatmentrep = filestart, 
                          mnburstGood = NA, sdburstGood = NA, nburstGood = NA,
                          mnburstGoodFair = NA, sdburstGoodFair = NA, nburstGoodFair = NA)

# create empty data frame to record gates with top 25% of inter-gate speeds within a single burst event; will use this to check that our 70cm tunnel is long enough for these fish
fastPos.comp = data.frame(treatmentrep = "EMPTY", burstID = as.factor(NA), 
                          burstQual = NA, 
                          fastVel = NA, fastGate = as.factor(NA), fastPos = NA)

# create empty data frame to collect the burst events that were recorded but not used in analysis (usually false-triggers); need to check and confirm the filtering critera are working well
check_events = data.frame(burstQual = "EMTPY", stalledAt = "EMPTY", BURST_NUMBER=NA, ORIENTATION=NA, START_TIME=NA,  
Gate00 = NA, Gate01=NA, Gate02=NA, Gate03=NA, Gate04=NA, Gate05=NA, Gate06=NA, Gate07=NA, Gate08=NA, Gate09 = NA, Gate10=NA, Gate11=NA, Gate12=NA, Gate13=NA, Gate14=NA, n.missed=NA)
```
  
    
Loop through all burst trials and fill in above dfs, and write out a pdf of burst speeds over multiple tunnel segments for manual/subjective evaluation of methods. This. Will. Be. Epic. 
```{r loop through trials and collect data}

# first define segment lengths to use in summarizing data
min_distance = 1.5       # only consider inter-gate distances greater than 1.5cm 
max_distance = 15        # only consider inter-gate distances less than 15cm 
write.file = "Yes"       # write out a file; don't use while troubleshooting

# set up folders for writing out data as you go
spp.yr.rawfilepath = "BurstExpt1_2023" # where the raw data files from raspPi are stored
spp.yr.figfolder = "Bursts_Outputfigures_Expt1_DS2023" # this folder should be created within the 'DS_Tagging/figures' folder before running this code
spp.yr.dataoutputfolder = "Bursts_Outputdata_Expt1_DS2023" # this folder should be created within the 'DS_Tagging/outputData' folder before running this code




#### Here is the EPIC LOOP ####
# for learning or troubleshooting, assign f to 1 (or 2 or 3 etc) then run each line within the loop directly and see what it does/where it's broken

for(f in 1:length(filestart)) {
  print(f) # useful for troubleshooting later, when things break
     filename = as.character(dir(paste0("../rawData/",spp.yr.rawfilepath), 
                                 pattern=filestart[f]))
          # for troubleshooting, use this;file structure diff when run as RMD vs console
          #filename = as.character(dir(paste0("rawData/",spp.yr.rawfilepath), 
          #                       pattern=filestart[f]))
     
     # create a folder within existing structure for each burst trial (if not already there)
     figureoutputfolder = paste0("../figures/",spp.yr.figfolder,"/",filestart[f])
         if (file.exists(figureoutputfolder) == FALSE) { dir.create(figureoutputfolder)}
      dataoutputfolder = paste0("../outputData/",spp.yr.dataoutputfolder,"/",filestart[f])
          if (file.exists(dataoutputfolder) == FALSE) { dir.create(dataoutputfolder)}

     ## read in all bursts for a fish
     dat = read.csv(paste0("../rawData/",spp.yr.rawfilepath,"/",filename)  )
       # remove last three rows of df that have only start/end/total time stamps
       dat = dat[1:(nrow(dat)-3),]  
       # if there is an extra empty column at the end, remove it here
       dat$X <- NULL
 
     ## add the leading zero inside the gate names (column names) for later organization
      shortnames = names(dat)[names(dat) %in% paste0("Gate",0:9)] 
      longnames = paste0(str_sub(shortnames,end=4),"0",str_sub(shortnames,start=5, end=5))
      names(dat)[names(dat) %in% shortnames] <- longnames
      
     gate_names <- names(dat)[grep("Gate",names(dat))] # pulls all the gate names to vector
     
      # check point during loop
     if(sum(nchar(gate_names)!=6) >0) print(paste("filestart, element#",f,filestart[f],"with error in Gate Names. Check loop around line 150"))
  
     
     ## pull trial-specific metadata from overall metadat file 'trial_specs'
     metadat = trial_specs[trial_specs$raspPI_filestart==filestart[f],]
      # ensure metadat is ordered by burst number
      metadat = metadat[order(metadat$burstnumb),]
      
     
       
  #### filter out gate trips not made by fish, using metadata ('stalledAt')
     # df with blank columns to be filled in with the following loop    
     dat2 = data.frame(burstQual=as.character(NA), stalledAt= as.character(NA), dat) 
    
     for(b in 1:nrow(dat2)) {    #  for each row in dat2 do the following:
       #  Use this line to troubleshoot if the loop is breaking;
       #   can see where in the loop something happens, and review that specific iteration
         #print(b) 
       #   pull metadat for corresponding burst 
       dat2$burstQual[b] <- metadat[b,"burstQual"]  
       #   translate 'stalledAt' number to Gate number
      finalgate = as.numeric(metadat[b,"stalledAt"])
       #   add 'stalledAt' gate number to dat2
      dat2$stalledAt[b] <- as.numeric(metadat[b,"stalledAt"])
      #   if fish never stalled, move to next burst
      if(is.na(finalgate)) next                    
      #   if fish stalled at final gate (14 in 2023), next 
      if(finalgate==14) next                       
      #  save column number where 'bad data' start so we can replace data from columns GateXX and after to remove from analysis
      badcol_index = finalgate+6               
      #  replace all timestamps from stall to end of tunnel with -99
      dat2[b,badcol_index:ncol(dat2)] <- -99  
     }
     
     # quantify how many gates were missed 
     for(m in 1:nrow(dat2)) {
       dat2$n.missed[m] = sum(is.na(dat2[m,c(5:ncol(dat2))]) )
      }
     
     # switch -99 to NA for rest of code
     dat2[is.na(dat2)] <- -99
    
     
     # remove burst events that didn't collect quality data (eg: gates triggered incorrectly, fish skipped at surface, etc), but first pull data from the gates that meet my tentative criteria for removal create a dataframe to check before moving on
     # currently criteria are those burst events where missed more than 6 gates (ie>=50%) 
     check_events_i = dat2[dat2$n.missed>6 | dat2$burstQual==-99,]
    
    
    check_events <<- rbind(check_events, check_events_i) 
       # double arrow saves object from loop into the global environment; else erased at end of loop
    
    # apply filter and remove poor burst events
     dat3 = dat2[dat2$burstQual != -99 & dat2$n.missed<7,]
      
    # Create an empty list of datafames for each burst in the target trial
     num_burst<-nrow(dat3)
     burst.df.list <- replicate(num_burst, data.frame()) 
    
    # adjust tunnel_specs t(fewer columns and diff names) for merge in next step
    tunnel_position = tunnel_specs[,c("GATE_ID","GATE_DISTANCES")]
     names(tunnel_position) = c("GATE_ID","POSITION")
     
    # Calulate Metrics for each burst attempt in target trial
    for (i in 1:num_burst){
      assign("temp.dat", dat3[i,],.GlobalEnv) #tidyverse, Ken's old code tidbit
      # convert from wide to long format; one line per gate vs  one line per burst event
      temp.dat.gathered <- gather(temp.dat, all_of(gate_names), 
                                  key = "GATE_ID",value = "TIMING") 

      # add  location in the tunnel (from tunnel_specs) to the times at that gate 
      temp.dat.gathered = merge(temp.dat.gathered, tunnel_position, all.x=T) 
        temp.dat.gathered = filter(temp.dat.gathered, TIMING!=-99)
      
      ## Use a pipe to calculate spd metrics from sequential positions and times
      temp.dat.gathered = temp.dat.gathered %>%
        # removes gates that were missed (no times); do this first for better calcs of spd
         filter(TIMING!=-99) %>%
        # removes row if time recorded was before the previous, unless the row was the first detection of the fish in the tunnel; do before spd calcs 
         filter(TIMING==0 | TIMING - lag(TIMING,1) >= 0) %>%
        # Calulate the difference in position between gates
         mutate("POSITION_DIFF" = POSITION - lag(POSITION,1)) %>% 
        # Create column of differences between two sequential timings
         mutate("TIMING_DIFF" = TIMING - lag(TIMING,1)) %>% 
        # Calculate velocity
         mutate("VELOCITY" = POSITION_DIFF/TIMING_DIFF) %>% 
        # Calculates differnce between two sequential velocities
         mutate("VELOCITY_DIFF" = VELOCITY - lag(VELOCITY,1)) %>%  
        # Calculate acceleration
         mutate("ACCEL" = VELOCITY_DIFF/TIMING_DIFF) 
      
    # set gates as factor levels so they are ordered in future plots  
    temp.dat.gathered$GATE_ID = factor(temp.dat.gathered$GATE_ID, 
                                       levels=c("Gate00", "Gate01", "Gate02", "Gate03", 
                                                "Gate04", "Gate05", "Gate06","Gate07",
                                                "Gate08", "Gate09", "Gate10", "Gate11", 
                                                "Gate12", "Gate13","Gate14"))  
     # stores each burst event as a dataframe in a list  
     burst.df.list[[i]]<-temp.dat.gathered 
          
    }
    
   # Filter to remove elements within list that have no data; they cause problems later;
   #  they should have been filtered out already with above filters, but final check
   burst.df.list = Filter(function(n) {sum(!is.na(n$TIMING_DIFF)) > 0}, burst.df.list)


   
  ## Write out to previously defined output folder, if writing files
    if(write.file=="Yes") {
       # convert from list to single dataframe for writing out
       rbind_burst.df.list = do.call(rbind, burst.df.list) 
   
        write.csv(rbind_burst.df.list,
                paste0(dataoutputfolder,"/Gate_by_Gate_metrics_",filestart[f],".csv"),
                row.names=F)  }
   
   
   
    #### Plot data for each burst ####
    if(write.file=="Yes") {

        pdf(paste0(figureoutputfolder,"/filtered_segmentBursts_",filestart[f],".pdf"),
            onefile=TRUE)
        for(i in 1:length(burst.df.list)) {
          if(nrow(burst.df.list[[i]]) == 0) {next} else {
            print ( ggplot(data = burst.df.list[[i]]) +
              geom_errorbarh(aes(xmax = as.numeric(GATE_ID), 
                                 xmin = as.numeric(lag(GATE_ID)), 
                                 y = VELOCITY, height = 0))+
              coord_cartesian(xlim=c(1,15), ylim=c(0,100))+
              scale_x_continuous(breaks=1:15,labels=levels(burst.df.list[[i]]$GATE_ID))+  
              ggtitle(paste("Inter-gate Velocities: Burst",i," (max segment length =",max_distance,")")) +
              ylab("Velocity (cm/s)")+
              xlab("Gate Number")+
              theme(axis.text.x = element_text(angle=90)) ) }
                   }
        dev.off()
      }

   
   
   
 
  #### Pull velocity metrics ####
   
    # Write function to pull mean of fastest 3 velocities per burst event,
    #  after dropping fastest one (object dd below notes how many fastest metrics to drop)
    
    topvel_func= function(x,n,d) { ## runs with x = either burst.df.list 
      vel.list = sort(x$VELOCITY, decreasing=TRUE) 
      n_vels <- length(vel.list)
      n_avg <- n
      n_dropped <- d
      if(n_vels<(n+d)) {mnvel=NA; sdvel=NA; n_avg<-0} else {
         mnvel = mean(vel.list[(d+1):(d+n)]) 
         sdvel = sd(vel.list[(d+1):(d+n)]) }
      return(data.frame(treatmentrep = filestart[f],
                        burstID = unique(x$BURST_NUMBER), 
                        burstQual = factor(unique(x$burstQual),
                                           levels=c("P","F","G")),
                        n_vels = n_vels,
                        n_avg = n_avg,
                        n_dropped = n_dropped,
                        start_side = unique(x$ORIENTATION),
                        mn.topburstvels = mnvel, 
                        sd.topburstvels = sdvel,
                        CV.topburstvels.perc = round(sdvel/mnvel*100,1) ) ) 
     }
     
    # select dd and nn, then apply function to burst.df.list and save output as a df
    dd = 1 # drop fastest dd
    nn = 3 # average remaining nn
    burst.mntopvels = do.call(rbind, lapply(burst.df.list, topvel_func, n=nn, d=dd)) 
    # returns NA vel for the brust if there are =< n velocity values measured
   
   
    if(write.file=="Yes") {
      write.csv(burst.mntopvels, paste0(dataoutputfolder,
                 "/Subjective_Rank_Mn_dropTop",dd,"_avgNext",nn,"_",filestart[f],".csv"),
                  row.names=F)
       
       pdf(paste0(figureoutputfolder,"/velTrends_within_trial_",filestart[f],".pdf"))
          print ( ggplot(data = burst.mntopvels, aes(x=burstID, y=mn.topburstvels)) +
              geom_errorbar(aes(ymax = mn.topburstvels+sd.topburstvels, 
                                 ymin = mn.topburstvels-sd.topburstvels), width=0.25)+
              geom_point(size=2.5)+  
              coord_cartesian(xlim=c(1,8), ylim=c(0,100))+
              ylab("Est. Max Velocity (cm/s)")+
              xlab("Burst Event")+
              theme_bw() )
        dev.off()
      
      }
    
    
    ## append to empty dataframe to collect all burst trials in one place for analysis  
      burst.topvels = rbind(burst.topvels, burst.mntopvels)

       
    ## look at how well subjective ranks corresponded with estimated burst speeds
      # boxplots of mean and sd top speeds within each subjective rank category
      burst.mntop.nona = burst.mntopvels[!is.na(burst.mntopvels$mn.topburstvels),]
      subjective_rank_spds = ggplot( data = burst.mntop.nona,
              aes(x=burstQual, y=mn.topburstvels)) +
              geom_boxplot(fill="grey95") +
              geom_point(size=3)+
              xlab("")+#"Subjective Quality Ranking (Poor, Fair, Good)")+ 
              ylab("Estimated Burst Vel\n(mn of 3 seg/event)")+
              theme_bw()
    
      subjective_rank_varspds = ggplot( data = burst.mntop.nona,
              aes(x=burstQual, y=sd.topburstvels)) +
              geom_boxplot(fill="grey95") +
              geom_point(size=3)+
              xlab("Subjective Quality Ranking (Poor, Fair, Good)")+ 
              ylab("SD of Burst Vels\n(sd of 3 seg/event)")+
              theme_bw()
      
      
      if(write.file=="Yes") {
        pdf(paste0(figureoutputfolder,"/Subjective_Rank_MnSd_dropTop",dd,"_avgNext",nn,"_",filestart[f],".pdf"), onefile=TRUE)
        
          subjective_rank_spds + subjective_rank_varspds + plot_layout(ncol=1)
          
        dev.off()
        }
      
       
    
    
    ### Function to pull the top 25% of speeds (measured at each sequential gate) 
      #  for each burst and identify where along the burst tunnel they are happening
     ## This was mostly for designing the burst tunnel before we built the smallest one, 
      #  as we wanted to confirm that a 70cm tunnel was long enough for sturgeon 
      #  (ie: fastest speeds were <70cm into tunnel)
      fastPos_func = function(x) { 
        fast.pos = which(x$VELOCITY > quantile(x$VELOCITY,.75, na.rm=T)) 
            # returns true/false vector of inter-gate speeds in the top 25% percentile
         if(length(fast.pos)==0) {return(NULL)} else {  
        fastVel = x$VELOCITY[fast.pos]   
            # new vector that includes the top 25% of measured spds
        fastGate = x$GATE_ID[fast.pos]   
            # gate ID that corresponds to fastest measures
        fastPos = x$POSITION[fast.pos]   
            # cm along tunnel that corresponds to fastest measures
        return(cbind(data.frame(treatmentrep = filestart[f],
                                burstID = unique(x$BURST_NUMBER), 
                                burstQual = unique(x$burstQual)),
                     fastVel, fastGate, fastPos) ) } # make a new df for each burst event
        }
      
      fastPos = do.call(rbind, lapply(burst.df.list, fastPos_func)) 
           # rbind all df created with the function above for the burst trial being 
           #  targetted in the current iteration of this giant loop
      fastPos$burstID = factor(fastPos$burstID, levels=c(1:15))
      fastPos$fastGate = factor(fastPos$fastGate)
      
      # check if desired, otherwise won't run plots
        # ggplot(fastPos, aes(y=fastVel,x=burstID, color=burstQual)) + geom_point() +
        #   theme_bw()
        # ggplot(fastPos, aes(x=fastGate, fill=burstQual)) +
        #   geom_histogram(stat="count", position="dodge", color="black") +
        #   scale_fill_viridis_d()+
        #   theme_bw()
      
      # append burst from current loop to an existing object that will accumulate ALL data
      fastPos.comp = rbind(fastPos.comp, fastPos)
      


    
    
 ### calculate metrics to output for spds
  mn.goodevents = burst.mntopvels[burst.mntopvels$burstQual=="G",]      
    mn.top3goodevents = mn.goodevents[rev(order(mn.goodevents$mn.topburstvels)),][1:3,]
       
  mn.goodfairevents = burst.mntopvels[burst.mntopvels$burstQual%in% c("G","F"),]      
    mn.top3goodfairevents = mn.goodfairevents[rev(order(mn.goodfairevents$mn.topburstvels)),][1:3,]     
    
  mn.burstvalue = mean(mn.top3goodevents$mn.topburstvels, na.rm=T)
    mn.burstvalue.gf = mean(mn.top3goodfairevents$mn.topburstvels, na.rm=T)
    
    sd.burstvalue = sd(mn.top3goodevents$mn.topburstvels, na.rm=T)
      sd.burstvalue.gf = sd(mn.top3goodfairevents$mn.topburstvels, na.rm=T)
   
    n.burstvalue = length(mn.goodevents$mn.topburstvels)
      n.burstvalue.gf = length(mn.goodfairevents$mn.topburstvels)

    
    # add them to the appropriate row in empty dataframe
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "mnburstGood"] <- mn.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "mnburstGoodFair"] <- mn.burstvalue.gf
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "sdburstGood"] <- sd.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "sdburstGoodFair"] <- sd.burstvalue.gf
     
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGood"] <- n.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGoodFair"] <- n.burstvalue.gf

}
```
PHEW! That was an epic loop. 



```{r clean up compilation df}
# remove one line used to start the df
burst.topvels2 = burst.topvels[burst.topvels$treatmentrep!="EMPTY",]
fastPos.comp2 = fastPos.comp[fastPos.comp$treatmentrep!="EMPTY",] 

# set fastPos gate order for factor
fastPos.comp2$fastGate = factor(fastPos.comp2$fastGate, 
                                levels=c("Gate00","Gate01","Gate02","Gate03",
                                         "Gate04","Gate05","Gate06","Gate07",
                                         "Gate08","Gate09","Gate10","Gate11",
                                         "Gate12","Gate13","Gate14"))



# add metadata and fix formatting
trial_specs_unique = unique(trial_specs[,c("raspPI_filestart","trialID","treatment", "spp","acclimstart","triallength","holdingtank","tunneltemp","sex","eggStage","fl_mm","mass_g")])

mean.topvels2 = merge(mean.topvels, trial_specs_unique, all.x=T, by.x="treatmentrep", by.y="raspPI_filestart") 

# remove NA burst estimates (or estimated with only one good or fair bursts)
mean.topvels2 = mean.topvels2[!is.na(mean.topvels2$sdburstGoodFair),]

# add BL/s column
mean.topvels2$mnburstGoodFair_bls = mean.topvels2$mnburstGoodFair/(mean.topvels2$fl_mm/10) 

```

```{r plots to evaluate study design}

  # look at where the fastest burst segment were (for next tunnel design)
  ggplot(fastPos.comp2, aes(y=fastVel, x=burstID, color=burstQual)) + 
      geom_point() + 
      theme_bw() 
    
  ggplot(fastPos.comp2, aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()
  
  ggplot(filter(fastPos.comp2, fastVel>20) , aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()

  # look at speed and trial order
  ggplot(mean.topvels2, aes(x=as.numeric(str_sub(trialID,2,3)), y=mnburstGoodFair)) + 
    geom_point() + 
    geom_smooth(method="lm") +
    xlab("TrialID") + ylab("Est Burst Velocity (cm/s)")+
    theme_bw()   
  
  # look at trial length within a concentration, and look at participation and burst speed
  ggplot(mean.topvels2, aes(y=triallength, x=treatment, fill=treatment)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey90","grey70",
                                 "darkslategray2","sandybrown",
                                 "cyan3","darkorange2"), 
                        labels=c("Full Control","Handling Control",
                                 "Lateral Surgery","Ventral Surgery",
                                 "Lateral Tagging","Ventral Tagging"),
                        name="Treatment Group") + 
      ylab("Trial Length (min)") + xlab("Surgical Treatment") + theme_bw()
  
        ggplot(mean.topvels2, aes(x=triallength, y=nburstGood, fill=treatment)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=treatment), n=4) + 
           scale_color_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
            facet_wrap(~treatment) + theme_bw()
        
        ggplot(mean.topvels2, aes(x=triallength, y=mnburstGoodFair_bls, fill=treatment)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=treatment), n=4) + 
            scale_color_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
            facet_wrap(~treatment) + theme_bw()

  # look at tank effects on growth, then on participation and burst speeds
  ggplot(mean.topvels2, aes(x=factor(holdingtank), y=fl_mm, fill=treatment)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
      theme_bw()
  
    
  summary(aov(lm(mass_g ~ treatment + holdingtank, data= mean.topvels2)))     
  summary(aov(lm(fl_mm ~ treatment + holdingtank, data= mean.topvels2)))  
  summary(aov(lm(nburstGoodFair ~ treatment + holdingtank, data= mean.topvels2)))  
  summary(aov(lm(mnburstGoodFair_bls ~ treatment + holdingtank, data= mean.topvels2)))  
  # Tank effects doesn't seem to be causing difference in growth or nburstGood 
```
  
  
```{r plot effects on Good burst number}
 
  # look at relationship between number of bursts and sd in bursts within a fish
  ggplot(mean.topvels2, aes(x=nburstGoodFair, y=mnburstGoodFair)) + 
    geom_point(aes(color=nburstGoodFair), size=3) + geom_smooth()

  ggplot(mean.topvels2, aes(x=nburstGoodFair, y=sdburstGoodFair)) + 
    geom_point(aes(color=nburstGoodFair), size=3) + geom_smooth()
  
  ggplot(filter(mean.topvels2, nburstGoodFair>3), aes(x=nburstGoodFair, y=mnburstGoodFair)) + 
    geom_point(aes(color=nburstGoodFair), size=3) + geom_smooth()
  
     table(mean.topvels2[mean.topvels2$nburstGoodFair>3,]$treatment)
 
```

```{r plots relating burst participation with speed}
  # look at relationship between estimated burst speeds and number of good bursts, by treatment group
     ggplot(filter(mean.topvels2, nburstGoodFair>3),
           aes(x=nburstGoodFair, y=mnburstGoodFair, color=treatment, group=treatment)) + 
      geom_point(size=4) + geom_smooth(n=4) + 
      scale_color_manual(values=c("grey90","grey70", "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
      facet_wrap(~treatment) + theme_bw()
  
    
    # look at relationship between burst participation and treatment
  ggplot(filter(mean.topvels2, nburstGoodFair>3), 
         aes(x=treatment, y=nburstGoodFair, fill=treatment)) + 
     geom_boxplot() +
     #geom_violin() +
     scale_fill_manual(values=c("grey90","grey70", "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
     ylab("n 'Good' bursts") + xlab("Experimental Treatment") +
    theme_bw()

  # test this statistically
   participant.model.3 = lm(nburstGoodFair ~ treatment, 
                           data = filter(mean.topvels2, nburstGoodFair>3))
    plot(participant.model.3) # meets assumptions okay, better ends for normal plot
    summary(aov(participant.model.3)) # no sig effect of treatment on burst participation
     TukeyHSD(aov(participant.model.3))
    

        
        
# look at relationship between burst quality and fish length
    ggplot(filter(mean.topvels2, nburstGoodFair>3), aes(x=fl_mm, y=nburstGoodFair)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("n 'Good' bursts") + xlab("fish length cm") + 
    theme_bw()
    
```

```{r lm relating burst participation with speed}

  # test this statistically
  participant.model.all = lm(nburstGood~log(CalcConc+1), data = mean.topvels2)
    plot(participant.model.all) # meets assumptions okay, normal plot ends are skewed
    summary((participant.model.all)) # no effect of treatment; effect size shows linear increase in number of good bursts with increasing conc. 
  participant.model.5 = lm(nburstGood~log(CalcConc+1), 
                           data = filter(mean.topvels2, nburstGood>5))
    plot(participant.model.5) # meets assumptions okay, better ends for normal plot
    summary((participant.model.5)) # sig effect of conc now, p=0.036; slightly stronger effect size and lower se; still linear increase in number of good bursts with increasing conc. 
    
    
      # test this statistically
      participant.model.allfair = lm(nburstGoodFair~log(CalcConc+1), data = mean.topvels2)
        plot(participant.model.allfair) # meets assumptions okay, normal plot ends skew down
        summary((participant.model.allfair)) # no effect of treatment; effect size shows linear increase in number of good bursts with increasing conc. 
      participant.model.5fair = lm(nburstGoodFair~log(CalcConc+1), 
                               data = filter(mean.topvels2, nburstGood>5))
        plot(participant.model.5fair) # meets assumptions okay, better ends for normal plot
        summary((participant.model.5fair)) # sig effect of conc now, p=0.038 slightly stronger effect size and lower se; still linear increase in number of good bursts with increasing conc. 

```

```{r plots of effects on burst speed} 

  # look at effect of fish size or mass on burst speeds
  ggplot(filter(mean.topvels2, nburstGoodFair>3), aes(x=fl_mm, y=mass_g)) + 
    geom_point() + geom_smooth() + theme_bw()

     # look at length-adjusted burst speeds (ie: bl/s)
       library(ggpubr)
       gghistogram(filter(mean.topvels2, nburstGoodFair>3), 
                   x="mnburstGoodFair_bls", y="..density..",
                   add="mean", add_density=TRUE, fill="grey50")
       
       ggplot(filter(mean.topvels2, nburstGoodFair>3), 
              aes(x=mnburstGoodFair_bls, color=factor(treatment), fill=factor(treatment))) + 
         geom_density(alpha=0.2, bw=2) + 
            scale_color_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
         theme_bw()

```
   
   
```{r report or paper plots}     
# plot points for each fish, jittered around the log of the treatments; presents same dataset but with more information
# this is the plot used for Ken's bay delta poster
set.seed(38)
mean.topvels2$random.offset = runif(n=nrow(mean.topvels2), min = -0.25, max=0.25)
mainplot = ggplot(filter(mean.topvels2, nburstGoodFair>3), 
                  aes(y=mnburstGoodFair, x=as.numeric(treatment)+random.offset)) + 
         geom_errorbar(aes(ymin=mnburstGoodFair-sdburstGoodFair,
                           ymax=mnburstGoodFair+sdburstGoodFair), width=0) + 
         geom_point(aes(size=nburstGoodFair, fill=treatment), pch=21, alpha=0.8) + 
         theme_bw() + 
         ylab("Est. Burst Swim Speed (cm/s)") +
         scale_x_continuous(breaks=1:6, 
                            labels=levels(mean.topvels2$treatment), 
                            name="Surgical Treatment Group")  +
         scale_size_continuous(breaks=c(4,6,8), name = "Number of\n'Good' Bursts") + 
           scale_fill_manual(values=c("grey90","grey70",
                                     "darkslategray2","sandybrown",
                                     "cyan3","darkorange2"), 
                            labels=c("Full Control","Handling Control",
                                     "Lateral Surgery","Ventral Surgery",
                                     "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
         theme_bw()

mainplot

  
  if(write.file=="Yes") {
    tiff("figures/Bursts_Outputfigures_2022WS/WS2022_Bif_BurstEstimates.tiff", 
         width=165, height=100, units="mm", res=300) 
    mainplot
    dev.off() }
```


```{r simple stats models}
filtered.moddat = filter(mean.topvels2, nburstGoodFair>3)

# experimental design checks
summary(aov(fl_mm ~treatment, data = filtered.moddat)) # no effect
summary(aov(mass_g ~ treatment, data = filtered.moddat)) # no effect
summary(aov(tunneltemp ~ treatment, data = filtered.moddat)) # effect!!!
 summarize(group_by(filtered.moddat, treatment), 
              meanTemp = mean(tunneltemp, na.rm=T), 
              sdTemp = sd(tunneltemp, na.rm=T))
        #  treatment     meanTemp sdTemp
        #  FC            12.8     0.300  
        #  HC            12.8     0.195
        #  LS            12.6     0.392
        #  VS *          12.6     0.332 
        #  LT            12.8     0.161
        #  VT            12.8     0.186
 TukeyHSD(aov(tunneltemp ~ treatment, data = filtered.moddat)) # no sig pair-wise difs, and effect size is small enough it doesn't seem relevant to the fish performance. 
 


# basic hypothesis test (effect of treatment on vel)
simplemod = lm(mnburstGoodFair_bls~treatment, data = filtered.moddat)
  plot(simplemod) # fits assumptions great
  summary(aov(simplemod)) # not significant p=0.181
  summarize(group_by(filtered.moddat, treatment), 
              estVel = mean(mnburstGoodFair, na.rm=T), 
              sdVel = sd(mnburstGoodFair, na.rm=T),
              estVelbls = mean(mnburstGoodFair_bls, na.rm=T), 
              sdVelbls = sd(mnburstGoodFair_bls, na.rm=T))
       # treatment estVel sdVel estVelbls sdVelbls
       # FC         118.   36.1      14.9     4.86
       # HC          87.   29.3      11.0     3.80
       # LS         112.   35.0      14.1     4.16
       # VS         113.   45.7      13.8     5.45
       # LT         100.   30.6      12.4     3.68
       # VT         110.   32.0      13.9     3.72

  # set custom contrasts to compare controls vs treatments   
  #    https://rcompanion.org/rcompanion/h_01.html
  library(car)
  library(emmeans)
  library(multcomp)
  # levels of treatment  are  "FC" "HC" "LS" "VS" "LT" "VT"
  Contrasts.all = list(FCvLS      =  c(1,   0,  -1,   0,   0,   0),
                   FCvVS      =  c(1,   0,   0,  -1,   0,   0), 
                   FCvLT      =  c(1,   0,   0,   0,  -1,   0),
                   FCvVT      =  c(1,   0,   0,   0,   0,  -1),
                   HCvLS      =  c(0,   1,  -1,   0,   0,   0),
                   HCvVS      =  c(0,   1,   0,  -1,   0,   0), 
                   HCvLT      =  c(0,   1,   0,   0,  -1,   0),
                   HCvVT      =  c(0,   1,   0,   0,   0,  -1))
  marginal = emmeans(simplemod, ~treatment)
  contrast(marginal, method = Contrasts.all, adjust="sidak")
         # contrast estimate   SE df t.ratio p.value
         # FCvLS       0.892 1.56 86  0.571  0.9988 
         # FCvVS       1.149 1.54 86  0.747  0.9924 
         # FCvLT       2.497 1.56 86  1.597  0.6197 
         # FCvVT       1.090 1.54 86  0.709  0.9947 
         # HCvLS      -3.092 1.62 86 -1.913  0.3856 
         # HCvVS      -2.835 1.59 86 -1.781  0.4800 
         # HCvLT      -1.487 1.62 86 -0.920  0.9719 
         # HCvVT      -2.894 1.59 86 -1.818  0.4525 
  
  # set custom contrasts to lump sham vs tag and L vs V locations   
  # levels of treatment  are  "FC" "HC" "LS" "VS" "LT" "VT"
  Contrasts = list(LvV      =  c(0,   0,   1,  -1,   1,  -1),
                   SvT      =  c(0,   0,   1,   1,  -1,  -1), 
                   CvL      =  c(1,   1,  -1,   0,  -1,   0),
                   CvV      =  c(1,   1,   0,  -1,   0,  -1),
                   CvS      =  c(1,   1,  -1,  -1,   0,   0),
                   CvT      =  c(1,   1,   0,   0,  -1,  -1))

  marginal = emmeans(simplemod, ~treatment)
  contrast(marginal, method = Contrasts, adjust="sidak")
      #  contrast estimate   SE df t.ratio p.value
      #  LvV        -1.150 2.21 86 -0.520  0.9962 
      #  SvT         1.546 2.21 86  0.699  0.9816 
      #  CvL        -0.595 2.25 86 -0.265  0.9999 
      #  CvV        -1.745 2.21 86 -0.788  0.9667 
      #  CvS        -1.943 2.23 86 -0.871  0.9466 
      #  CvT        -0.397 2.23 86 -0.178  1.0000 
      
  
  # still no sig differences when lump groups together; we do see that the largest est vel differences occur between the control vs ventral group (control slower), and the control vs sham group (control slower). When we compare the lateral vs ventral the model estimates that the lateral tagged group is slower. But because the handing control is the slowest, and there is no statistical significance, I don't think there is any evidence that the tagging process is altering the burst capabilities after 7 days of recovery. 
  
  # exclude handling control, just to see
  Contrasts2 = list(CvL      =  c(2,   0,  -1,   0,  -1,   0),
                   CvV       =  c(2,   0,   0,  -1,   0,  -1),
                   CvS       =  c(2,   0,  -1,  -1,   0,   0),
                   CvT       =  c(2,   0,   0,   0,  -1,  -1))

  marginal = emmeans(simplemod, ~treatment)
  contrast(marginal, method = Contrasts2, adjust="sidak")
       # contrast estimate   SE df t.ratio p.value
       # CvL          3.39 2.69 86  1.258  0.3167 
       # CvV          2.24 2.66 86  0.841  0.8728 
       # CvS          2.04 2.68 86  0.762  0.9072 
       # CvT          3.59 2.68 86  1.339  0.5566   
  # without the slow HC group, the full control is faster than all treatment group combinations. The biggest differences are between the FC and lateral groups and the tagged groups, and the smallest difference from FC is the sham groups; this amtches our expectations more so than the prior contrasts. However, there is still no statistical support for differences that are unlikely to be due to chance. 
```  
  
```{r full stats model for comparison}  
# kitchen sink model for dredging (explore effects of study design/constraints)

fullmod = lm(mnburstGoodFair_bls ~ treatment + nburstGoodFair + tunneltemp + fl_mm + triallength, data = filtered.moddat, na.action="na.fail" ) # could (should?) make this a lmer with holding tank as the random effect, but makes inference harder later

 plot(fullmod) # looks good!
 
 summary(aov(fullmod)) # tunneltemp significant, nburst close
 
 dredge(fullmod)
   # best model with only treatment and tunnel temp
   # 2nd best (dAIC = 0.70) adds nburst
   # 3rd best (dAIC = 1.1) drops treatment *most parsimonious within dAIC<2
 
summarize(group_by(filter(mean.topvels2, nburstGoodFair>3), treatment), 
           n.reps = n(),
           mean.vel = mean(mnburstGoodFair_bls, na.rm=T), 
           sd.vel = sd(mnburstGoodFair_bls, na.rm=T),
           mean.nburstGood = mean(nburstGoodFair, na.rm=T),
           mean.triallength = mean(triallength, na.rm=T),
           mean.temp = mean(tunneltemp, na.rm=T),
           mean.fl_mm = mean(fl_mm, na.rm=T))
#  treatment n.reps mean.vel   sd.vel mean.nburstGood mean.triallength mean.temp mean.fl_mm
#         FC     16 14.94438 4.860154        6.062500          9.18750  12.77500   79.75000
#         HC     14 10.95997 3.803696        6.428571         10.35714  12.83571   79.64286
#         LS     15 14.05243 4.161743        6.133333         10.73333  12.60667   79.80000
#         VS     16 13.79489 5.451122        6.000000          9.37500  12.56875   82.00000
#         LT     15 12.44692 3.681385        6.066667         10.46667  12.82000   80.46667
#         VT     16 13.85421 3.715551        5.812500          9.12500  12.75000   79.00000

 
 
fullmod.participant= lm(nburstGoodFair ~ treatment + triallength + tunneltemp + fl_mm, data = filtered.moddat, na.action="na.fail")
 plot(fullmod.participant) # not super clean, but probably okay
 summary(aov(fullmod.participant)) # no effects are significant
 
dredge(fullmod.participant)  
 # best model only tunnel temp (and intercept)
 # second best with only intercept (dAIC=0.72) *most parsimonious within dAIC<2
 
```
 
## From this data I conclude that there is not a clear nor strong effect of the tagging procedure on burst capacity after 7 days of recovery. There may be a small signal indicating that the lateral location reduces burst speeds more than the ventral location, and that tag burden reduces the burst speed more than simply the surgical procedure. But again, no statistical significance. 

## We did these tests with 14-16 replicates. With the high variance among individuals (CV = ~30%) we will need to use more replicates to detect a significant effect. 

## We saw average estimates of 11-15 (sd ~4) bl/s and differences of 2-3 bl/s. If we put these values into a power analysis (mean = 13.5, sd = 4, minimum difference to detect = 3) it suggests we use a sample size of 23 per group (with 3 groups). If we want to detect significance with a difference of 2 bl/s, we should use 50 per group. 
