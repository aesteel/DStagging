---
title: "Delta Smelt Tagging - Burst analysis Expt 3 "
author: "Anna Steel"
date: "11/02/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lme4)
library(circular)
library(patchwork)
library(MuMIn)

```

This code segment reads in the measurements of inter-laser distance taken from the tunnel (taken immediately before or after trials) and entered in the same format as Ken used in his initial tests in 2019 and 2020.   
  
It then manipulates these dataframes/tibbles to use merge with the burst files for each fish and calculate velocities.   
```{r read tunnel data}
# if running from the DS_Tagging project in AES laptop then the base wd is "/Users/Anna/Documents/ResearchGit/SturgContam"; but the wd will be wherever the project file is located and the pathnames here should be relative to that location. Two '..' in the file name indicates to go back one folder in the directory structure.

## Set up gate distances for use in code
tunnel_specs23 <- read_csv("../rawData/DS_Burst_Tunnel_Specs_08_2023_SG.csv")

tunnel_specs = tunnel_specs23[,c("GATE_ID_L", "INTERGATE_DISTANCES_CM","GATE_DISTANCES_CM_L")]
names(tunnel_specs) = c("GATE_ID","INTERGATE_DISTANCES","GATE_DISTANCES")

# We have code that will let us use each intergate distance, including overlapping gates, not just the sequential gates. For the sturgeon, The resulting numbers weren't that different, and I'm uncomfortable with the pseudoreplication of averaging across segments that overlap, So I've deleted it for now, and we will use only the sequential gates to keep the code more concise. 

```      
    
```{r read trial metadata}

# pull metadata for index to all trials and metadata
trial_specs <- read.csv("../rawData/Expt3_30day_DS2023_Burst_MetaTrialdat.csv")


 # tidy up data types within the df
 trial_specs$trialdate = readr::parse_date(trial_specs$trialdate)
 trial_specs$tagdate =  readr::parse_date(trial_specs$tagdate)
 
 trial_specs$accstart = readr::parse_time(trial_specs$accstart, "%I:%M:%S %p")
 trial_specs$trialstart = readr::parse_time(trial_specs$trialstart, "%I:%M:%S %p")
 trial_specs$trialend = readr::parse_time(trial_specs$trialend, "%I:%M:%S %p")
  
 trial_specs$treatment = as.factor(trial_specs$treatment) 
 trial_specs$holdingtank = as.factor(trial_specs$holdingtank) 
 trial_specs$sex = as.factor(trial_specs$sex) 
 trial_specs$startside = as.factor(trial_specs$startside) 
 trial_specs$burstQual = as.factor(trial_specs$burstQual)
 trial_specs$stimQual = as.factor(trial_specs$stimQual) 
 
 trial_specs$nFalseStart[is.na(trial_specs$nFalseStart)] <- 0
 
 # add padding zeros to the tag Hexcodes
 trial_specs$tagID = str_pad(trial_specs$tagID,4, pad="0")
 
 # Calculate trial length
 trial_specs$triallength = as.numeric(difftime(trial_specs$trialend, trial_specs$trialstart))
 
 
# vector of all the file names to be considered in the analysis
filestart <- unique(trial_specs$raspPI_filestart)


```


There are endless ways to use the burst events from one individual to estimate a 'burst speed' for that fish. See Ken's paper to understand what he considered and selected, and then look at if/how much those align with the methods considered here. For the juvenile sturgeon bursts, I selected to drop the fastest burst segment from each burst event, then average the next three highest segments to get an estimate of burst speed for that burst event. For each individual (multiple burst events) I then averaged the fastest three burst events to get an estimated burst speed for the individual. We will try that here as our first pass, and see how the results look. 

```{r create empty df for collection}

# create empty dataframe to record mean of top 3 burst velocities, after removing top 1; for each burst of each fish
burst.topvels = data.frame(treatmentrep = "EMPTY", burstID = NA, 
                           burstQual = as.factor(NA),
                          n_vels = NA, n_avg = NA, n_dropped = NA, start_side = NA,
                          mn.topburstvels = NA, sd.topburstvels = NA, CV.topburstvels.perc = NA)

# create empty dataframe to record above burst velocity averaged across the fastest three pre-filtered 'good' trials for each fish, as well as sd of bursts and and N good bursts for that individual (potential index of participation)
mean.topvels = data.frame(treatmentrep = filestart, 
                          mnburstGood = NA, sdburstGood = NA, nburstGood = NA,
                          mnburstGoodFair = NA, sdburstGoodFair = NA, nburstGoodFair = NA)

# create empty data frame to record gates with top 25% of inter-gate speeds within a single burst event; will use this to check that our 70cm tunnel is long enough for these fish
fastPos.comp = data.frame(treatmentrep = "EMPTY", burstID = as.factor(NA), 
                          burstQual = NA, 
                          fastVel = NA, fastGate = as.factor(NA), fastPos = NA)

# create empty data frame to collect the burst events that were recorded but not used in analysis (usually false-triggers); need to check and confirm the filtering critera are working well
check_events = data.frame(burstQual = "EMTPY", stalledAt = "EMPTY", BURST_NUMBER=NA, ORIENTATION=NA, START_TIME=NA,  
Gate00 = NA, Gate01=NA, Gate02=NA, Gate03=NA, Gate04=NA, Gate05=NA, Gate06=NA, Gate07=NA, Gate08=NA, Gate09 = NA, Gate10=NA, Gate11=NA, Gate12=NA, Gate13=NA, Gate14=NA, n.missed=NA)

```
  
    
Loop through all burst trials and fill in above dfs, and write out a pdf of burst speeds over multiple tunnel segments for manual/subjective evaluation of methods. This. Will. Be. Epic. 
```{r loop through trials and collect data}

# first define segment lengths to use in summarizing data
min_distance = 1.5       # only consider inter-gate distances greater than 1.5cm 
max_distance = 15        # only consider inter-gate distances less than 15cm 
write.file = "Yes"       # write out a file; don't use while troubleshooting

# set up folders for writing out data as you go
spp.yr.rawfilepath = "BurstExpt3_30d_2023" # where the raw data files from raspPi are stored
spp.yr.figfolder = "Bursts_Outputfigures_Expt3_30d_DS2023" # this folder should be created within the 'DS_Tagging/figures' folder before running this code
spp.yr.dataoutputfolder = "Bursts_Outputdata_Expt3_30d_DS2023" # this folder should be created within the 'DS_Tagging/outputData' folder before running this code




#### Here is the EPIC LOOP ####
# for learning or troubleshooting, assign f to 1 (or 2 or 3 etc) then run each line within the loop directly and see what it does/where it's broken

for(f in 1:length(filestart)) {
  print(f) # useful for troubleshooting later, when things break
     filename = as.character(dir(paste0("../rawData/",spp.yr.rawfilepath), 
                                 pattern=filestart[f]))
          # for troubleshooting, use this;file structure diff when run as RMD vs console
          #filename = as.character(dir(paste0("rawData/",spp.yr.rawfilepath), 
          #                       pattern=filestart[f]))
     
     # create a folder within existing structure for each burst trial (if not already there)
     figureoutputfolder = paste0("../figures/",spp.yr.figfolder,"/",filestart[f])
         if (file.exists(figureoutputfolder) == FALSE) { dir.create(figureoutputfolder)}
      dataoutputfolder = paste0("../outputData/",spp.yr.dataoutputfolder,"/",filestart[f])
          if (file.exists(dataoutputfolder) == FALSE) { dir.create(dataoutputfolder)}

     ## read in all bursts for a fish
     dat = read.csv(paste0("../rawData/",spp.yr.rawfilepath,"/",filename)  )
       # remove last three rows of df that have only start/end/total time stamps
       dat = dat[1:(nrow(dat)-3),]  
       # if there is an extra empty column at the end, remove it here
       dat$X <- NULL
 
     ## add the leading zero inside the gate names (column names) for later organization
      shortnames = names(dat)[names(dat) %in% paste0("Gate",0:9)] 
      longnames = paste0(str_sub(shortnames,end=4),"0",str_sub(shortnames,start=5, end=5))
      names(dat)[names(dat) %in% shortnames] <- longnames
      
     gate_names <- names(dat)[grep("Gate",names(dat))] # pulls all the gate names to vector
     
      # check point during loop
     if(sum(nchar(gate_names)!=6) >0) print(paste("filestart, element#",f,filestart[f],"with error in Gate Names. Check loop around line 150"))
  
     
     ## pull trial-specific metadata from overall metadat file 'trial_specs'
     metadat = trial_specs[trial_specs$raspPI_filestart==filestart[f],]
      # ensure metadat is ordered by burst number
      metadat = metadat[order(metadat$burstnumb),]
      
     
       
  #### filter out gate trips not made by fish, using metadata ('burstTo'); used to use stalledAt but I think the data was collected a little differently this time. 
     # df with blank columns to be filled in with the following loop    
     dat2 = data.frame(burstQual=as.character(NA), burstTo= as.character(NA), dat, Notes = as.character(NA))
    
     for(b in 1:nrow(dat2)) {    #  for each row in dat2 do the following:
       #  Use this 'print' line to troubleshoot if the loop is breaking;
       #   can see where in the loop something happens, and review that specific iteration
        # print(b) 
       #   pull metadat for corresponding burst 
      dat2$burstQual[b] <- as.character(metadat[b,"burstQual"])
       #   add 'burstTo' gate number to dat2
      dat2$burstTo[b] <- as.numeric(metadat[b,"burstTo"])
       finalgate = as.numeric(dat2$burstTo[b])
      #   if there isn't burst data, move to next burst for now; maybe delete later
       
      # add notes so later we can remove data for rows with notes for 'fail'
       dat2$Notes[b] = metadat$Notes[b]
      if(is.na(finalgate)) next            #print("finaldate=NA")#
      #   if fish stalled at final gate (14 in 2023), next 
      if(finalgate==14) next               #print("finaldate=14")#        
      #  save column number where 'bad data' start so we can replace data from columns GateXX and after to remove from analysis
      badcol_index = finalgate+7 # six columns gate columns, then add one more to jump to the first 'bad column'    ; CHECK THIS - may be that the numbers used in the notes do not correspond with the numbers used in the RaspPI code          
      #  replace all timestamps from end of burst to end of tunnel with -99
      dat2[b,badcol_index:(ncol(dat2)-1)] <- -99  # -1 to save the notes
     }
     
     # remove rows with 'fail' 
     dat2 = dat2[!(str_detect(dat2$Notes,"FAIL")),]
     
     # quantify how many gates were missed 
     for(m in 1:nrow(dat2)) {
       dat2$n.missed[m] = sum(is.na(dat2[m,c(5:ncol(dat2))]) )
      }
     
     # switch -99 to NA for rest of code
     dat2[is.na(dat2)] <- -99
    
     
     # remove burst events that didn't collect quality data (eg: gates triggered incorrectly, fish skipped at surface, etc), but first pull data from the gates that meet my tentative criteria for removal create a dataframe to check before moving on
     # currently criteria are those burst events where missed more than 6 gates (ie>=50%) 

     
## add back in later ###########    
#     check_events_i = dat2[dat2$n.missed>6 | dat2$burstQual==-99,]
    
#    check_events <<- rbind(check_events, check_events_i) 
   # double arrow saves object from loop into the global environment; else erased at end of loop
#####################
     
     
    # apply filter and remove poor burst events
     dat3 = dat2[dat2$burstQual != -99 & dat2$n.missed<7,]
      
    # Create an empty list of datafames for each burst in the target trial
     num_burst<-nrow(dat3)
     burst.df.list <- replicate(num_burst, data.frame()) 
    
    # adjust tunnel_specs t(fewer columns and diff names) for merge in next step
    tunnel_position = tunnel_specs[,c("GATE_ID","GATE_DISTANCES")]
     names(tunnel_position) = c("GATE_ID","POSITION")
     
    # Calulate Metrics for each burst attempt in target trial
    for (i in 1:num_burst){
      assign("temp.dat", dat3[i,],.GlobalEnv) #tidyverse, Ken's old code tidbit
      # convert from wide to long format; one line per gate vs  one line per burst event
      temp.dat.gathered <- gather(temp.dat, all_of(gate_names), 
                                  key = "GATE_ID",value = "TIMING") 

      # add  location in the tunnel (from tunnel_specs) to the times at that gate 
      temp.dat.gathered = merge(temp.dat.gathered, tunnel_position, all.x=T) 
        temp.dat.gathered = filter(temp.dat.gathered, TIMING!=-99)
      
      ## Use a pipe to calculate spd metrics from sequential positions and times
      temp.dat.gathered = temp.dat.gathered %>%
        # removes gates that were missed (no times); do this first for better calcs of spd
         filter(TIMING!=-99) %>%
        # removes row if time recorded was before the previous, unless the row was the first detection of the fish in the tunnel; do before spd calcs 
         filter(TIMING==0 | TIMING - lag(TIMING,1) >= 0) %>%
        # Calulate the difference in position between gates
         mutate("POSITION_DIFF" = POSITION - lag(POSITION,1)) %>% 
        # Create column of differences between two sequential timings
         mutate("TIMING_DIFF" = TIMING - lag(TIMING,1)) %>% 
        # Calculate velocity
         mutate("VELOCITY" = POSITION_DIFF/TIMING_DIFF) %>% 
        # Calculates differnce between two sequential velocities
         mutate("VELOCITY_DIFF" = VELOCITY - lag(VELOCITY,1)) %>%  
        # Calculate acceleration
         mutate("ACCEL" = VELOCITY_DIFF/TIMING_DIFF) 
      
    # set gates as factor levels so they are ordered in future plots  
    temp.dat.gathered$GATE_ID = factor(temp.dat.gathered$GATE_ID, 
                                       levels=c("Gate00", "Gate01", "Gate02", "Gate03", 
                                                "Gate04", "Gate05", "Gate06","Gate07",
                                                "Gate08", "Gate09", "Gate10", "Gate11", 
                                                "Gate12", "Gate13","Gate14"))  
     # stores each burst event as a dataframe in a list  
     burst.df.list[[i]]<-temp.dat.gathered 
          
    }
    
   # Filter to remove elements within list that have no data; they cause problems later;
   #  they should have been filtered out already with above filters, but final check
   burst.df.list = Filter(function(n) {sum(!is.na(n$TIMING_DIFF)) > 0}, burst.df.list)


   
  ## Write out to previously defined output folder, if writing files
    if(write.file=="Yes") {
       # convert from list to single dataframe for writing out
       rbind_burst.df.list = do.call(rbind, burst.df.list) 
   
        write.csv(rbind_burst.df.list,
                paste0(dataoutputfolder,"/Gate_by_Gate_metrics_",filestart[f],".csv"),
                row.names=F)  }
   
   
   
    #### Plot data for each burst ####
    if(write.file=="Yes") {

        pdf(paste0(figureoutputfolder,"/filtered_segmentBursts_",filestart[f],".pdf"),
            onefile=TRUE)
        for(i in 1:length(burst.df.list)) {
          if(nrow(burst.df.list[[i]]) == 0) {next} else {
            print ( ggplot(data = burst.df.list[[i]]) +
              geom_errorbarh(aes(xmax = as.numeric(GATE_ID), 
                                 xmin = as.numeric(lag(GATE_ID)), 
                                 y = VELOCITY, height = 0))+
              coord_cartesian(xlim=c(1,15), ylim=c(0,100))+
              scale_x_continuous(breaks=1:15,labels=levels(burst.df.list[[i]]$GATE_ID))+  
              ggtitle(paste("Inter-gate Velocities: Burst",i," (max segment length =",max_distance,")")) +
              ylab("Velocity (cm/s)")+
              xlab("Gate Number")+
              theme(axis.text.x = element_text(angle=90)) ) }
                   }
        dev.off()
      }

   
   
   
 
  #### Pull velocity metrics ####
   
    # Write function to pull mean of fastest 3 velocities per burst event,
    #  after dropping fastest one (object dd below notes how many fastest metrics to drop)
    
    topvel_func= function(x,n,d) { ## runs with x = either burst.df.list 
      vel.list = sort(x$VELOCITY, decreasing=TRUE) 
      n_vels <- length(vel.list)
      n_avg <- n
      n_dropped <- d
      if(n_vels<(n+d)) {mnvel=NA; sdvel=NA; n_avg<-0} else {
         mnvel = mean(vel.list[(d+1):(d+n)]) 
         sdvel = sd(vel.list[(d+1):(d+n)]) }
      return(data.frame(treatmentrep = filestart[f],
                        burstID = unique(x$BURST_NUMBER), 
                        burstQual = factor(unique(x$burstQual),
                                           levels=c("P","F","G")),
                        n_vels = n_vels,
                        n_avg = n_avg,
                        n_dropped = n_dropped,
                        start_side = unique(x$ORIENTATION),
                        mn.topburstvels = mnvel, 
                        sd.topburstvels = sdvel,
                        CV.topburstvels.perc = round(sdvel/mnvel*100,1) ) ) 
     }
     
    # select dd and nn, then apply function to burst.df.list and save output as a df
    dd = 1 # drop fastest dd
    nn = 3 # average remaining nn
    burst.mntopvels = do.call(rbind, lapply(burst.df.list, topvel_func, n=nn, d=dd)) 
    # returns NA vel for the brust if there are =< n velocity values measured
   
   
    if(write.file=="Yes") {
      write.csv(burst.mntopvels, paste0(dataoutputfolder,
                 "/Subjective_Rank_Mn_dropTop",dd,"_avgNext",nn,"_",filestart[f],".csv"),
                  row.names=F)
       
       pdf(paste0(figureoutputfolder,"/velTrends_within_trial_",filestart[f],".pdf"))
       
          print ( ggplot(data = burst.mntopvels, aes(x=burstID, y=mn.topburstvels)) +
              geom_errorbar(aes(ymax = mn.topburstvels+sd.topburstvels, 
                                 ymin = mn.topburstvels-sd.topburstvels), width=0.25)+
              geom_point(size=2.5)+  
              coord_cartesian(xlim=c(1,8), ylim=c(0,100))+
              ylab("Est. Max Velocity (cm/s)")+
              xlab("Burst Event")+
              theme_bw() )
          
        dev.off()
      
      }
    
    
    ## append to empty dataframe to collect all burst trials in one place for analysis  
      burst.topvels = rbind(burst.topvels, burst.mntopvels)

       
    ## look at how well subjective ranks corresponded with estimated burst speeds
      # boxplots of mean and sd top speeds within each subjective rank category
      burst.mntop.nona = burst.mntopvels[!is.na(burst.mntopvels$mn.topburstvels),]
      subjective_rank_spds = ggplot( data = burst.mntop.nona,
              aes(x=burstQual, y=mn.topburstvels)) +
              geom_boxplot(fill="grey95") +
              geom_point(size=3)+
              xlab("")+#"Subjective Quality Ranking (Poor, Fair, Good)")+ 
              ylab("Estimated Burst Vel\n(mn of 3 seg/event)")+
              theme_bw()
    
      subjective_rank_varspds = ggplot( data = burst.mntop.nona,
              aes(x=burstQual, y=sd.topburstvels)) +
              geom_boxplot(fill="grey95") +
              geom_point(size=3)+
              xlab("Subjective Quality Ranking (Poor, Fair, Good)")+ 
              ylab("SD of Burst Vels\n(sd of 3 seg/event)")+
              theme_bw()
      
      
      if(write.file=="Yes") {
        pdf(paste0(figureoutputfolder,"/Subjective_Rank_MnSd_dropTop",dd,"_avgNext",nn,"_",filestart[f],".pdf"), onefile=TRUE)
        
          subjective_rank_spds + subjective_rank_varspds + plot_layout(ncol=1)
          
        dev.off()
        
        }
      
       
    
    
    ### Function to pull the top 25% of speeds (measured at each sequential gate) 
      #  for each burst and identify where along the burst tunnel they are happening
     ## This was mostly for designing the burst tunnel before we built the smallest one, 
      #  as we wanted to confirm that a 70cm tunnel was long enough for sturgeon 
      #  (ie: fastest speeds were <70cm into tunnel)
      fastPos_func = function(x) { 
        fast.pos = which(x$VELOCITY > quantile(x$VELOCITY,.75, na.rm=T)) 
            # returns true/false vector of inter-gate speeds in the top 25% percentile
         if(length(fast.pos)==0) {return(NULL)} else {  
        fastVel = x$VELOCITY[fast.pos]   
            # new vector that includes the top 25% of measured spds
        fastGate = x$GATE_ID[fast.pos]   
            # gate ID that corresponds to fastest measures
        fastPos = x$POSITION[fast.pos]   
            # cm along tunnel that corresponds to fastest measures
        return(cbind(data.frame(treatmentrep = filestart[f],
                                burstID = unique(x$BURST_NUMBER), 
                                burstQual = unique(x$burstQual)),
                     fastVel, fastGate, fastPos) ) } # make a new df for each burst event
        }
      
      fastPos = do.call(rbind, lapply(burst.df.list, fastPos_func)) 
           # rbind all df created with the function above for the burst trial being 
           #  targetted in the current iteration of this giant loop
      fastPos$burstID = factor(fastPos$burstID, levels=c(1:15))
      fastPos$fastGate = factor(fastPos$fastGate)
      
      # check if desired, otherwise won't run plots
        # ggplot(fastPos, aes(y=fastVel,x=burstID, color=burstQual)) + geom_point() +
        #   theme_bw()
        # ggplot(fastPos, aes(x=fastGate, fill=burstQual)) +
        #   geom_histogram(stat="count", position="dodge", color="black") +
        #   scale_fill_viridis_d()+
        #   theme_bw()
      
      # append burst from current loop to an existing object that will accumulate ALL data
      fastPos.comp = rbind(fastPos.comp, fastPos)
      


    
    
 ### calculate metrics to output for spds
  mn.goodevents = burst.mntopvels[burst.mntopvels$burstQual=="G",]      
    mn.top3goodevents = mn.goodevents[rev(order(mn.goodevents$mn.topburstvels)),][1:3,]
       
  mn.goodfairevents = burst.mntopvels[burst.mntopvels$burstQual%in% c("G","F"),]      
    mn.top3goodfairevents = mn.goodfairevents[rev(order(mn.goodfairevents$mn.topburstvels)),][1:3,]     
    
  mn.burstvalue = mean(mn.top3goodevents$mn.topburstvels, na.rm=T)
    mn.burstvalue.gf = mean(mn.top3goodfairevents$mn.topburstvels, na.rm=T)
    
    sd.burstvalue = sd(mn.top3goodevents$mn.topburstvels, na.rm=T)
      sd.burstvalue.gf = sd(mn.top3goodfairevents$mn.topburstvels, na.rm=T)
   
    n.burstvalue = length(mn.goodevents$mn.topburstvels)
      n.burstvalue.gf = length(mn.goodfairevents$mn.topburstvels)

    
    # add them to the appropriate row in empty dataframe
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "mnburstGood"] <- mn.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "mnburstGoodFair"] <- mn.burstvalue.gf
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "sdburstGood"] <- sd.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "sdburstGoodFair"] <- sd.burstvalue.gf
     
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGood"] <- n.burstvalue
     mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGoodFair"] <- n.burstvalue.gf

}
```
PHEW! That was an epic loop. 



```{r clean up compilation df}
# remove one line used to start the df
burst.topvels2 = burst.topvels[burst.topvels$treatmentrep!="EMPTY",]
fastPos.comp2 = fastPos.comp[fastPos.comp$treatmentrep!="EMPTY",] 

# set fastPos gate order for factor
fastPos.comp2$fastGate = factor(fastPos.comp2$fastGate, 
                                levels=c("Gate00","Gate01","Gate02","Gate03",
                                         "Gate04","Gate05","Gate06","Gate07",
                                         "Gate08","Gate09","Gate10","Gate11",
                                         "Gate12","Gate13","Gate14"))



# add metadata and fix formatting
trial_specs_unique = unique(trial_specs[,c("raspPI_filestart","trialID","treatment", "spp","accstart","triallength","holdingtank","tunneltemp","sex","fl_mm","mass_g")])

mean.topvels2 = merge(mean.topvels, trial_specs_unique, all.x=T, by.x="treatmentrep", by.y="raspPI_filestart") 

# remove NA burst estimates (or estimated with only one good or fair bursts)
mean.topvels2 = mean.topvels2[!is.na(mean.topvels2$sdburstGoodFair),]

# add BL/s column
mean.topvels2$mnburstGoodFair_bls = mean.topvels2$mnburstGoodFair/(mean.topvels2$fl_mm/10) 

# remove cold temp

mean.topvels2 = mean.topvels2[mean.topvels2$tunneltemp >12,]

```

```{r plots to evaluate study design}

  # look at where the fastest burst segment were (for next tunnel design)
  ggplot(fastPos.comp2, aes(y=fastVel, x=burstID, color=burstQual)) + 
      geom_point() + 
      theme_bw() 
    
  ggplot(fastPos.comp2, aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()
  
  ggplot(filter(fastPos.comp2, fastVel>20) , aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()

  # look at speed and trial order
  ggplot(mean.topvels2, aes(x=as.numeric(str_sub(trialID,2,3)), y=mnburstGoodFair)) + 
    geom_point() + 
    geom_smooth(method="lm") +
    xlab("TrialID") + ylab("Est Burst Velocity (cm/s)")+
    theme_bw()   
  
  # look at speed and sex 
  ggplot(mean.topvels2, aes(x=factor(sex), y=nburstGoodFair)) + 
    geom_boxplot() + 
    geom_jitter(width=.15) +
    xlab("Sex") + ylab("N 'Good' bursts")+
    theme_bw()   
  
  ggplot(mean.topvels2, aes(x=factor(sex), y=mnburstGoodFair_bls)) + 
    geom_boxplot()+
    geom_jitter(width=.15) +
    xlab("Sex") + ylab("Est Burst Velocity (bl/s)")+
    theme_bw()   
  
  # look at speed and temp
  ggplot(mean.topvels2, aes(x=tunneltemp, y=mnburstGoodFair_bls)) + 
    geom_point(aes(color=sex))+
    geom_smooth(method="lm")+
    xlab("Water Temperature") + ylab("Est Burst Velocity (bl/s)")+
    theme_bw()  
    
  # look at trial length within a treatment, and look at participation and burst speed
  ggplot(mean.topvels2, aes(y=triallength, x=treatment, fill=treatment)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey90","cyan3","darkorange2"), 
                        labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                        name="Treatment Group") + 
      ylab("Trial Length (min)") + xlab("Surgical Treatment") + theme_bw()
  
        ggplot(mean.topvels2, aes(x=triallength, y=nburstGood, fill=treatment)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=treatment), n=4) + 
           scale_color_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
            facet_wrap(~treatment) + theme_bw()
        
        ggplot(mean.topvels2, aes(x=triallength, y=mnburstGoodFair_bls, fill=treatment)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=treatment), n=4) + 
            scale_color_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey90", "cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
            facet_wrap(~treatment) + theme_bw()

  # look at tank effects on growth, then on participation and burst speeds
  ggplot(mean.topvels2, aes(x=factor(holdingtank), y=fl_mm, fill=treatment)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey90", "cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
      theme_bw()

  ggplot(mean.topvels2, aes(x=treatment, y=fl_mm, fill=treatment)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey90", "cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
      theme_bw()
  
    
  summary(aov(lm(mass_g ~ treatment + holdingtank, data= mean.topvels2)))     
  summary(aov(lm(fl_mm ~ treatment + holdingtank, data= mean.topvels2)))  
  summary(aov(lm(nburstGoodFair ~ treatment + holdingtank, data= mean.topvels2)))  
  summary(aov(lm(mnburstGoodFair_bls ~ treatment + holdingtank, data= mean.topvels2)))  
  summary(aov(lm(mnburstGoodFair_bls ~ treatment + holdingtank + mass_g, data= mean.topvels2)))  
  # Tank effects are present, and are non-significant but close to sig (p=0.08) when predicting burst speed. Not burst number or size of fish though. 
  
```
 
```{r plot effects on Good burst number}
 
  # look at relationship between number of bursts and sd in bursts within a fish
  ggplot(mean.topvels2, aes(x=nburstGoodFair, y=mnburstGoodFair)) + 
    geom_point(aes(color=nburstGoodFair), size=3) + geom_smooth()

  ggplot(mean.topvels2, aes(x=nburstGoodFair, y=sdburstGoodFair)) + 
    geom_point(aes(color=nburstGoodFair), size=3) + geom_smooth()
  
      table(mean.topvels2$treatment)
 
```

```{r plots relating burst participation with speed}
  # look at relationship between estimated burst speeds and number of good bursts, by treatment group
     ggplot(filter(mean.topvels2, nburstGoodFair>3),
           aes(x=nburstGoodFair, y=mnburstGoodFair, color=treatment, group=treatment)) + 
      geom_point(size=4) + geom_smooth(n=4) + 
      scale_color_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
      facet_wrap(~treatment) + theme_bw()
  
    
    # look at relationship between burst participation and treatment
  ggplot(filter(mean.topvels2, nburstGoodFair>3), 
         aes(x=treatment, y=nburstGoodFair, fill=treatment)) + 
     #geom_boxplot() +
     geom_violin() +
     scale_fill_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
     ylab("n 'Good' bursts") + xlab("Experimental Treatment") +
    theme_bw()

  # test this statistically
   participant.model.3 = lm(nburstGoodFair ~ treatment, 
                           data = filter(mean.topvels2, nburstGoodFair>3))
    plot(participant.model.3) # meets assumptions okay, better ends for normal plot
    summary(aov(participant.model.3)) # no sig effect of treatment on burst participation
     TukeyHSD(aov(participant.model.3))
    

        
        
# look at relationship between burst quality and fish length
    ggplot(filter(mean.topvels2, nburstGoodFair>3), aes(x=fl_mm, y=nburstGoodFair)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("n 'Good' bursts") + xlab("fish length cm") + 
    theme_bw()
    
```


```{r plots of effects on burst speed} 

  # look at effect of fish size or mass on burst speeds
  ggplot(mean.topvels2, #filter(mean.topvels2, nburstGoodFair>3), 
         aes(x=fl_mm, y=mass_g)) + 
    geom_point() + geom_smooth() + theme_bw()

     # look at length-adjusted burst speeds (ie: bl/s)
       library(ggpubr)
       gghistogram(mean.topvels2, #filter(mean.topvels2, nburstGoodFair>3), 
                   x="mnburstGoodFair_bls", y="..density..",
                   add="mean", add_density=TRUE, bins=12, fill="grey50")
       
       ggplot(mean.topvels2, #filter(mean.topvels2, nburstGoodFair>3), 
              aes(x=mnburstGoodFair_bls, color=factor(treatment), fill=factor(treatment))) + 
         geom_density(alpha=0.2, bw=3) + 
            scale_color_manual(values=c("grey70","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey70", "cyan3","darkorange2"), 
                            labels=c("Full Control", "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
         theme_bw()
       
       
    # filter dataset so treatment groups are simliar in fl and number
     filt.mean.topvels2 = filter(mean.topvels2, fl_mm>65 & fl_mm<81)
        table(filt.mean.topvels2$treatment)
            # FC LT VT 
            # 18 16 17
        summarize(group_by(filt.mean.topvels2, treatment), 
                  minFL = min(fl_mm), maxFL = max(fl_mm), medianFL = median(fl_mm))
             # treatment minFL maxFL medianFL
             #        FC    66    80       76.5
             #        LT    68    80       76
             #        VT    69    77       72

        ggplot(filt.mean.topvels2,
              aes(x=mnburstGoodFair_bls, color=factor(treatment), fill=factor(treatment))) + 
         geom_density(alpha=0.2, bw=4) + 
            scale_color_manual(values=c("grey70","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group", 
                            guide=F) + 
            scale_fill_manual(values=c("grey70", "cyan3","darkorange2"), 
                            labels=c("Full Control", "Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
         theme_bw()
        
```
   
   
```{r report or paper plots}     
# plot points for each fish, jittered around the log of the treatments; presents same dataset but with more information
# this is the plot used for Ken's bay delta poster
set.seed(38)
filt.mean.topvels2$random.offset = runif(n=nrow(filt.mean.topvels2), min = -0.25, max=0.25)

filt.mean.topvels2 = filt.mean.topvels2 %>%
  mutate(sdburstGoodFair_bls = (sdburstGoodFair/mnburstGoodFair)*mnburstGoodFair_bls )
  # use Coef Var to translate mn & sd in absolute to bls

mainplot.filt = ggplot(filt.mean.topvels2, #filter(mean.topvels2, nburstGoodFair>3), 
                  aes(y=mnburstGoodFair_bls, x=as.numeric(treatment)+random.offset)) + 
         geom_errorbar(aes(ymin=mnburstGoodFair_bls-sdburstGoodFair_bls,
                           ymax=mnburstGoodFair_bls+sdburstGoodFair_bls), width=0) + 
         geom_point(aes(size=nburstGoodFair, fill=treatment), pch=21, alpha=0.8) + 
         theme_bw() + 
         ylab("Est. Burst Swim Speed (bl/s)") +
         scale_x_continuous(breaks=1:3, 
                            labels=levels(mean.topvels2$treatment), 
                            name="Surgical Treatment Group")  +
         scale_size_continuous(breaks=c(2,4,6), name = "Number of\n'Good' Bursts") + 
           scale_fill_manual(values=c("grey90","cyan3","darkorange2"), 
                            labels=c("Full Control","Lateral Tagging","Ventral Tagging"),
                            name="Treatment Group") + 
         theme_bw()

mainplot.filt

  
  if(write.file=="Yes") {
    tiff("figures/Bursts_Outputfigures_Expt3_DS2023/Expt3_7day_DS2023_BurstEstimates_sizeFilt.tiff", 
         width=165, height=100, units="mm", res=300) 
    mainplot.filt
    dev.off() }
```


```{r simple stats models}

# experimental design checks
summary(aov(fl_mm ~ treatment, data = filtered.moddat)) # near effect
summary(aov(mass_g ~ treatment, data = filtered.moddat)) # no effect
summary(aov(tunneltemp ~ treatment, data = filtered.moddat)) # no effect
 summarize(group_by(filt.mean.topvels2, treatment), 
              meanTemp = mean(tunneltemp, na.rm=T), 
              sdTemp = sd(tunneltemp, na.rm=T))
        #  treatment     meanTemp sdTemp
        #  FC            12.7     0.244  
        #  LT            12.8     0.294
        #  VT            12.7     0.306
 TukeyHSD(aov(fl_mm ~ treatment, data = filt.mean.topvels2)) # no sig pair-wise difs 


# basic hypothesis test (effect of treatment on vel)
simplemod = lm(mnburstGoodFair_bls~treatment, data = filt.mean.topvels2)
  plot(simplemod) # fits assumptions great
  summary(aov(simplemod)) # not significant p=0.181
  summarize(group_by(filt.mean.topvels2, treatment), 
              estVel = mean(mnburstGoodFair, na.rm=T), 
              sdVel = sd(mnburstGoodFair, na.rm=T),
              estVelbls = mean(mnburstGoodFair_bls, na.rm=T), 
              sdVelbls = sd(mnburstGoodFair_bls, na.rm=T),
              meanFL = mean(fl_mm, na.rm=T) )
       # treatment   estVel  sdVel estVelbls sdVelbls   meanFL
       #        FC   129.3    47.6     17.4      6.6     74.4
       #        LT   121.4    42.0     16.3      5.7     74.9
       #        VT   113.1    31.5     15.6.     4.5     72.6

  
  # set custom contrasts to compare controls vs treatments   
  #    https://rcompanion.org/rcompanion/h_01.html
  library(car)
  library(emmeans)
  library(multcomp)
  # levels of treatment  are  "FC" "LT" "VT"
  Contrasts.all = list(FCvLT  =  c(1,  -1,   0),
                   FCvVT      =  c(1,   0,  -1), 
                   LTvVT      =  c(0,   1,  -1))
  marginal = emmeans(simplemod, ~treatment)
  contrast(marginal, method = Contrasts.all, adjust="sidak")
         # contrast estimate   SE df t.ratio p.value
         # FCvLT       1.144 1.95 48   0.586  0.9153
         # FCvVT       1.841 1.91 48   0.958  0.7164
         # LTvVT       0.697 1.98 48   0.352  0.9795
  
```  
  
  
  
```{r full stats model for comparison}  

     filt.mean.topvels2 = filter(mean.topvels2, fl_mm>65 & fl_mm<81)

# kitchen sink model for dredging (explore effects of study design/constraints)

fullmod = lm(mnburstGoodFair_bls ~ treatment + nburstGoodFair + tunneltemp + fl_mm + sex, data = filt.mean.topvels2, na.action="na.fail" ) # could (should?) make this a lmer with holding tank as the random effect, but makes inference harder later

 plot(fullmod) # looks good!
 
 summary(aov(fullmod)) # tunneltemp is significant (after removed cold outlier with leverage), 
                       # treatment and sex least significant
 
 dredge(fullmod)
   # best model with only tunnel temp (but none really good; weight here only 20%)
   # 2nd best (dAIC = 0.50) adds fl
   # 3rd best (dAIC = 1.38) adds fl and #good burst
 
 Contrasts.all = list(FCvLT  =  c(1,  -1,   0),
                   FCvVT      =  c(1,   0,  -1), 
                   LTvVT      =  c(0,   1,  -1))
  marginal = emmeans(fullmod, ~treatment)
  contrast(marginal, method = Contrasts.all, adjust="sidak")
 
  
  
fullmod.participant= lm(nburstGoodFair ~ treatment + triallength + tunneltemp + fl_mm + sex, data = filt.mean.topvels2, na.action="na.fail")
 plot(fullmod.participant) # not super clean, but probably okay
 summary(aov(fullmod.participant)) # sex is significant here; temp nearly is
 
dredge(fullmod.participant)  
 # best model sex, tunnel temp, and treatment group (p=0.2); weight = 15%
 # second best drops treatment (dAIC=0.44, weight = 12%) *most parsimonious within dAIC<2
 
  # levels of treatment  are  "FC" "LT" "VT"
  Contrasts.all = list(FCvLT  =  c(1,  -1,   0),
                   FCvVT      =  c(1,   0,  -1), 
                   LTvVT      =  c(0,   1,  -1))
  marginal = emmeans(fullmod.participant, ~treatment)
  contrast(marginal, method = Contrasts.all, adjust="sidak")
     #   contrast estimate    SE df t.ratio p.value
     #   FCvLT    -0.00862 0.449 43  -0.019  1.0000
     #   FCvVT     0.90425 0.457 43   1.980  0.1537
     #   LTvVT     0.91286 0.476 43   1.920  0.1736
   # greatest participation from LT, then FC, then VT; no significance
  
  
```
 
## From this data I conclude that there is not a clear nor strong effect of the tagging procedure on burst capacity after 7 days of recovery. There may be a small signal indicating that the lateral location reduces burst speeds more than the ventral location, but it is very small if it is present at all, and no statistical significance. 

## We did these tests with 16-18 replicates, and still didn't see any significant differences. There was smaller CV in burst speeds this time (16-24%, vs 30% from Expt 1). 

## We saw slightly faster average estimates with an IQR from 12-20 bl/s and differences of 1.3 bl/s between the means for FC and VT. There were effects of size and water temp before data filtering, so I removed one cold outlier that had highleverage (11.6C; resulted in increased effect of temp), and I subset the data to equalize the length and sample size between groups. After that (removed larger fish from FC and VT) there was nearly no effect of treatment on burst speed. 

## I have not done an exhautive cleaning of the dataset to idenfity outliers based on speeds or notes; only removed those burst that were noted with "fail" in the comments. This *may* change results a little but I doubt it would alter things very much. 


